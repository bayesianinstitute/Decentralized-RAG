{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loding and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faiza\\Music\\llmResearch\\rag\\env\\Lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import  PyPDFDirectoryLoader\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_directory_pdf(directory_path):\n",
    "    loader = PyPDFDirectoryLoader(directory_path)\n",
    "    docs = loader.load()\n",
    "    return docs\n",
    "\n",
    "\n",
    "def text_splitter(document):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=2000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    texts = text_splitter.split_documents(document)\n",
    "\n",
    "    return texts\n",
    "\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# Load PDF Files\n",
    "DATA_DIR = Path(\"./data\")\n",
    "data = load_directory_pdf(DATA_DIR)\n",
    "\n",
    "document=text_splitter(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make sure to `pip install openai` first\n",
    "from openai import OpenAI\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "def get_embedding(text, model=\"nomic-ai/nomic-embed-text-v1.5-GGUF\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "from openai import OpenAI\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "import uuid\n",
    "def get_embedding(text, model=\"nomic-ai/nomic-embed-text-v1.5-GGUF\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB Successfully created :law_docs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from qdrant_client import QdrantClient,models\n",
    "\n",
    "\n",
    "# Qdrant\n",
    "QDRANT_HOST = \"http://localhost:6333\"  # Local Qdrant\n",
    "QDRANT_COLLECTION = \"law_docs\"\n",
    "\n",
    "\n",
    "\n",
    "qclient = QdrantClient(url=QDRANT_HOST)\n",
    "\n",
    "\n",
    "\n",
    "def createDB(collectionName):\n",
    "        if qclient.collection_exists(collection_name=f\"{collectionName}\"):\n",
    "                print(f\"Vector DB already exits :{collectionName}\")\n",
    "                return\n",
    "        \n",
    "        print(f\"Vector DB Successfully created :{collectionName}\")\n",
    "        \n",
    "        return qclient.create_collection(\n",
    "                collection_name=f\"{collectionName}\",\n",
    "                vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),)\n",
    "\n",
    "\n",
    "createDB(QDRANT_COLLECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embed_and_store(chunks,QDRANT_COLLECTION):\n",
    "\n",
    "    \"\"\"Embeds text chunks and stores them in Qdrant.\"\"\"\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        embedding = get_embedding(chunk.page_content)\n",
    "        # print(f\"{i} : {embedding}\")\n",
    "        qclient.upsert(\n",
    "            collection_name=QDRANT_COLLECTION,\n",
    "            points=[\n",
    "                models.PointStruct(\n",
    "                id= f'{uuid.uuid4()}', vector= embedding, payload= {\"data\":chunk.page_content,\"metadata\":chunk.metadata}),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "\n",
    "embed_and_store(document,QDRANT_COLLECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant information:\n",
      "Score  : 0.7758323\n",
      "Data :\n",
      " 28 Get a Social Security Number\n",
      "As a permanent resident, you are eligible for a Social Security number, \n",
      "which is a number assigned to you by the U.S. government. It helps the government keep track of your earnings and the benefits you can receive. Y our Social Security number is also used by financial institutions and other agencies, such as schools, to identify you. You may be asked for your Social Security number when you rent an apartment or buy a home.\n",
      "Social Security is a U.S. government program that \n",
      "provides benefits for certain retired workers and their families, certain disabled workers and their families, and certain family members of deceased workers. The government department in charge of Social Security is called the Social Security Administration (SSA). \n",
      "Find the Social Security office closest to you by:\n",
      "● Looking on the SSA website, www.socialsecurity.gov. For Spanish, visit \n",
      "www.segurosocial.gov/espanol. The website also has limited information available in several other languages.\n",
      "● Calling 1-800-772-1213 or 1-800-325-0778 (for hearing impaired) between 7 a.m. and 7 p.m. Free interpreter services are available.\n",
      "If You Do Not Speak English\n",
      "The Social Security office can provide an interpreter free of charge to help you apply \n",
      "for a Social Security number. When you call the Social Security office, tell the person \n",
      "who answers the phone that you do not speak English. They will find an interpreter to help. You can also get assistance from an interpreter when you visit the Social Security office.\n",
      "The Social Security Administration website contains helpful information for people new \n",
      "to the United States. The “Other Languages” section of the website has information about Social Security in several \n",
      "languages. Visit www.socialsecurity.gov; for Spanish, see www.segurosocial.gov/espanol.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def query_documents(query):\n",
    "    \"\"\"Searches Qdrant for relevant documents.\"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    return  qclient.search(\n",
    "        collection_name=QDRANT_COLLECTION,\n",
    "        query_vector=query_embedding,\n",
    "        limit=1,\n",
    "    )[0]\n",
    "\n",
    "\n",
    "# Example user query\n",
    "user_query = \"How Get a Social Security Number\"\n",
    "result = query_documents(user_query)\n",
    "print(\"Relevant information:\")\n",
    "\n",
    "score=result.score\n",
    "context=result.payload['data']\n",
    "print(\"Score  :\",score)\n",
    "print(\"Data :\\n\",context)\n",
    "print(\"--\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a lawyer, I'd be happy to help you navigate the process of obtaining a Social Security number as a permanent resident.\n",
      "\n",
      "To get a Social Security number, you can follow these steps:\n",
      "\n",
      "1. Find a Social Security office near you: You can find the closest Social Security office by visiting the SSA website (www.socialsecurity.gov) or calling 1-800-772-1213.\n",
      "2. Make an appointment: It's recommended to make an appointment before visiting the office, especially if you're not fluent in English. This will ensure that an interpreter is available to assist you during your visit.\n",
      "3. Gather required documents: You'll need to bring proof of identity and immigration status to the Social Security office. Acceptable documents include:\n",
      "\t* A valid passport\n",
      "\t* An employment authorization document (EAD)\n",
      "\t* A visa (if applicable)\n",
      "4. Fill out Form SS-5: When you visit the Social Security office, you'll be given a copy of Form SS-5, Application for a Social Security Card. Fill it out completely and accurately to ensure that your application is processed correctly.\n",
      "5. Apply for your Social Security number: Take the completed form to the Social Security office and submit it in person. The SSA representative will review your application and provide you with a Social Security card.\n",
      "\n",
      "Additional tips:\n",
      "\n",
      "* If you don't speak English, don't worry! The SSA offers free interpreter services to help you communicate during your visit or over the phone.\n",
      "* You can also get assistance from an interpreter when you visit the Social Security office. Just let them know that you need an interpreter when you schedule your appointment.\n",
      "* Make sure to bring all required documents and identification with you to the Social Security office.\n",
      "\n",
      "Remember, it's essential to follow these steps carefully to ensure that your application is processed correctly. If you have any questions or concerns, don't hesitate to reach out to a lawyer or the SSA for guidance."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt_Template=f\"\"\" You are Lawyer\n",
    "\n",
    "here is the question : {user_query}\n",
    "\n",
    "and addition context to support answer  {context}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "systemPrompt=\"You are helpful assistant that handle user query and give answer and only answer to user question and use it context rather than take information from outside system  \"\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "  \n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\":systemPrompt },\n",
    "    {\"role\": \"user\", \"content\": prompt_Template}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "llm_response=\"\"\n",
    "# Iterate over the stream of responses\n",
    "for chunk in completion:\n",
    "  # Print the text from each chunk\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    # Print the text from each chunk\n",
    "    llm_response += chunk.choices[0].delta.content\n",
    "    print(chunk.choices[0].delta.content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evulating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Coroutine\n",
    "from deepeval.models import DeepEvalBaseLLM\n",
    "from openai import OpenAI\n",
    "import asyncio\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class customLMStudio(DeepEvalBaseLLM):\n",
    "    def __init__(self, model=\"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\"):\n",
    "        self.model = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "        self.model_name = model\n",
    "\n",
    "    def load_model(self, *args, **kwargs):\n",
    "        return self.model\n",
    "    \n",
    "    def generate(self, prompt: str) -> str:\n",
    "        client = self.load_model()\n",
    "        completion = client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Your helpful AI for Evaluation\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    \n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        # Use asyncio.to_thread to run the blocking generate method in a separate thread\n",
    "        return self.generate(prompt=prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.model_name\n",
    "\n",
    "c = customLMStudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey! It looks like you accidentally sent an empty message. Is there something on your mind that you'd like to talk about or ask? I'm here to help with any questions or topics you'd like to discuss!\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.generate(\"Hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.get_model_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object customLMStudio.a_generate at 0x0000029E2D57D560>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.a_generate(\"Hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa3b2f660ae4d5eafefc42421ce9d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319e7b7571b54fe084c5d879bcad3d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "The score is 0.67 because although the output addresses some concerns, it also includes an irrelevant statement ('We offer') that does not directly answer the original question about fitting shoes.\n",
      "Evaluating test cases...\n",
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Answer Relevancy (score: 0.0, threshold: 0.7, strict: False, evaluation model: lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF, reason: The score is 0.00 because the actual output provided statements that were completely unrelated to the input question, discussing shoe refunds instead of addressing the issue of poorly fitting shoes., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What if these shoes don't fit?\n",
      "  - actual output: We offer a 30-day full refund at no extra cost.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: ['We offer a 40-day full refund at no extra cost']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Tests finished! Run \u001b[32m\"deepeval login\"\u001b[0m to view evaluation results on the web.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TestResult(success=False, metrics_metadata=[MetricMetadata(metric='Answer Relevancy', threshold=0.7, success=False, score=0.0, reason='The score is 0.00 because the actual output provided statements that were completely unrelated to the input question, discussing shoe refunds instead of addressing the issue of poorly fitting shoes.', strict_mode=False, evaluation_model='lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF', error=None, evaluation_cost=None, verbose_logs='Statements:\\n[\\n    \"We offer a 30-day full refund\",\\n    \"at no extra cost\"\\n]\\n\\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"no\",\\n        \"reason\": \"The statements provided are about shoe refunds and are not related to the input question, which asks about what to do if shoes don\\'t fit.\"\\n    }\\n]')], input=\"What if these shoes don't fit?\", actual_output='We offer a 30-day full refund at no extra cost.', expected_output=None, context=None, retrieval_context=['We offer a 40-day full refund at no extra cost'])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "actual_output = \"We offer a 30-day full refund at no extra cost.\"\n",
    "\n",
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=customLMStudio(),\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What if these shoes don't fit?\",\n",
    "    actual_output=actual_output,\n",
    "    retrieval_context=[\"We offer a 40-day full refund at no extra cost\"]\n",
    "\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e6cdcd47a74c0281cbb0750eab662d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f742bb9db994c85a17269dd5d2d8e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "The score is 1.00 because the response perfectly addresses the concern raised in the input without any irrelevant statements.\n",
      "Evaluating test cases...\n",
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4, reason: The score is 1.00 because the response perfectly addressed the concern about the shoes not fitting., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What if these shoes don't fit?\n",
      "  - actual output: We offer a 30-day full refund at no extra cost.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: ['We offer a 40-day full refund at no extra cost']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Tests finished! Run \u001b[32m\"deepeval login\"\u001b[0m to view evaluation results on the web.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TestResult(success=True, metrics_metadata=[MetricMetadata(metric='Answer Relevancy', threshold=0.7, success=True, score=1.0, reason='The score is 1.00 because the response perfectly addressed the concern about the shoes not fitting.', strict_mode=False, evaluation_model='gpt-4', error=None, evaluation_cost=0.026369999999999998, verbose_logs='Statements:\\n[\\n    \"We offer a 30-day full refund at no extra cost.\"\\n]\\n\\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]')], input=\"What if these shoes don't fit?\", actual_output='We offer a 30-day full refund at no extra cost.', expected_output=None, context=None, retrieval_context=['We offer a 40-day full refund at no extra cost'])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "actual_output = \"We offer a 30-day full refund at no extra cost.\"\n",
    "\n",
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4\",\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What if these shoes don't fit?\",\n",
    "    actual_output=actual_output,\n",
    "    retrieval_context=[\"We offer a 40-day full refund at no extra cost\"]\n",
    "\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaf7b4404ce4d7188e42355bbcc2ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83e582ad9c64e929c21b3095d80ee22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "The score is 1.00 because the only node in the retrieval context directly addresses the issue of the shoes not fitting.\n",
      "Evaluating test cases...\n",
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Contextual Precision (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4, reason: The score is 1.00 because the only node in the retrieval context directly addresses the user's concern about shoes not fitting, hence its high relevance and top ranking., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What if these shoes don't fit?\n",
      "  - actual output: We offer a 300-day full refund at no extra cost.\n",
      "  - expected output: You are eligible for a 30 day full refund at no extra cost.\n",
      "  - context: None\n",
      "  - retrieval context: ['All customers are eligible for a 30 day full refund at no extra cost.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Tests finished! Run \u001b[32m\"deepeval login\"\u001b[0m to view evaluation results on the web.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TestResult(success=True, metrics_metadata=[MetricMetadata(metric='Contextual Precision', threshold=0.7, success=True, score=1.0, reason=\"The score is 1.00 because the only node in the retrieval context directly addresses the user's concern about shoes not fitting, hence its high relevance and top ranking.\", strict_mode=False, evaluation_model='gpt-4', error=None, evaluation_cost=0.030809999999999997, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The text \\'All customers are eligible for a 30 day full refund at no extra cost.\\' directly addresses the concern about shoes not fitting.\"\\n    }\\n]')], input=\"What if these shoes don't fit?\", actual_output='We offer a 300-day full refund at no extra cost.', expected_output='You are eligible for a 30 day full refund at no extra cost.', context=None, retrieval_context=['All customers are eligible for a 30 day full refund at no extra cost.'])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import ContextualPrecisionMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "actual_output = \"We offer a 300-day full refund at no extra cost.\"\n",
    "\n",
    "# Replace this with the expected output from your RAG generator\n",
    "expected_output = \"You are eligible for a 30 day full refund at no extra cost.\"\n",
    "\n",
    "# Replace this with the actual retrieved context from your RAG pipeline\n",
    "retrieval_context = [\"All customers are eligible for a 30 day full refund at no extra cost.\"]\n",
    "\n",
    "metric = ContextualPrecisionMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4\",\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What if these shoes don't fit?\",\n",
    "    actual_output=actual_output,\n",
    "    expected_output=expected_output,\n",
    "    retrieval_context=retrieval_context\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "evaluate([test_case], [metric])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
